{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classifier\n",
    "\n",
    "This notebook will cover basically the same steps as the previous one, but this time we will use a different dataset and a different model. We will use the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset, which consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. The dataset is divided into 50,000 training images and 10,000 testing images. The classes are mutually exclusive and there is no overlap between them.\n",
    "\n",
    "My name is Bruno, aka (Awhux), and this is a course I'm taking to learn more about Machine Learning and Deep Learning. I'm using this notebook to take notes and to share my experience with others. I hope you enjoy it!\n",
    "\n",
    "## Useful notes\n",
    "\n",
    "- [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset\n",
    "- [CIFAR-10 python version](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)\n",
    "\n",
    "- [TensorFlow](https://www.tensorflow.org/)\n",
    "- [Keras](https://keras.io/)\n",
    "\n",
    "- [Google Colab](https://colab.research.google.com/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When you use colab, you can easily change some options here.\n",
    "# If you're seen this code, just double click in this cell and change the options.\n",
    "\n",
    "# If you're using vscode, you may need update some options listed here\n",
    "\n",
    "# If you're using vscode, you may need to set this to True\n",
    "install_packages = False  # @param {type:\"boolean\"}\n",
    "use_gpu = True  # @param {type:\"boolean\"}\n",
    "\n",
    "images_download_url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "download_file_name = 'cifar-10-python.tar.gz'\n",
    "extract_to = 'images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import tarfile\n",
    "\n",
    "import requests\n",
    "\n",
    "import pickle\n",
    "\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "    if len(gpus) >= 1:\n",
    "        try:\n",
    "            # Enable all GPUs\n",
    "            tf.config.experimental.set_visible_devices(gpus, 'GPU')\n",
    "\n",
    "            # Set memory growth\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "                print(f\"Enabled {gpu.name}\")\n",
    "        except RuntimeError as e:\n",
    "            # Visible devices must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "else:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Download and extract our images\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_download_progress(count, block_size, total_size):\n",
    "    percent = int(count * block_size * 100 / total_size)\n",
    "    print(f\"\\r{bcolors.OKCYAN}Downloading images: {percent}%{bcolors.ENDC}\", end='')\n",
    "\n",
    "\n",
    "def download_images():\n",
    "    if not os.path.exists(extract_to):\n",
    "        os.mkdir(extract_to)\n",
    "    if not os.path.exists(os.path.join(extract_to, download_file_name)):\n",
    "        r = requests.get(images_download_url, stream=True)\n",
    "        with open(os.path.join(extract_to, download_file_name), 'wb') as f:\n",
    "            total_length = int(r.headers.get('content-length'))\n",
    "            for chunk in r.iter_content(chunk_size=1024):\n",
    "                f.write(chunk)\n",
    "                get_download_progress(f.tell(), 1024, total_length)\n",
    "        print(f\"\\r{bcolors.OKGREEN}Downloaded images{bcolors.ENDC}\")\n",
    "    else:\n",
    "        print(f\"{bcolors.OKGREEN}Images already downloaded{bcolors.ENDC}\")\n",
    "\n",
    "    if not os.path.exists(os.path.join(extract_to, 'cifar-10-batches-py')):\n",
    "        print(\"Extracting images...\")\n",
    "        tar = tarfile.open(os.path.join(\n",
    "            extract_to, download_file_name), \"r:gz\")\n",
    "        tar.extractall(extract_to)\n",
    "        tar.close()\n",
    "    else:\n",
    "        print(f\"{bcolors.OKGREEN}Images already extracted{bcolors.ENDC}\")\n",
    "\n",
    "\n",
    "def unpicke_images():\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in range(1, 6):\n",
    "        with open(os.path.join(extract_to, 'cifar-10-batches-py', f'data_batch_{i}'), 'rb') as f:\n",
    "            data = pickle.load(f, encoding='bytes')\n",
    "            images.append(data[b'data'])\n",
    "            labels.append(data[b'labels'])\n",
    "    images = np.concatenate(images)\n",
    "    labels = np.concatenate(labels)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "class print_colored:\n",
    "    def __init__(self, color):\n",
    "        self.color = color\n",
    "\n",
    "    def __enter__(self):\n",
    "        print(self.color, end='')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        print(bcolors.ENDC, end='')\n",
    "\n",
    "\n",
    "download_images()\n",
    "\n",
    "# print(f\"{bcolors.OKGREEN}Images shape: {images.shape}{bcolors.ENDC}\")\n",
    "# Images shape: (50000, 3072)\n",
    "# print(f\"{bcolors.OKGREEN}Labels shape: {labels.shape}{bcolors.ENDC}\")\n",
    "# Labels shape: (50000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading image dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images():\n",
    "    import random\n",
    "\n",
    "    # Unpickle images, basically this is a numpy array\n",
    "    # with shape (50000, 3072), we want to reshape it to\n",
    "    # (50000, 3, 32, 32) and move the axis to the last.\n",
    "    # Why we need to do this? Because we want to use\n",
    "    # Conv2D layer in our model, and Conv2D layer\n",
    "    # requires the input shape to be (batch_size, height, width, channels)\n",
    "    # So we need to reshape our images to (50000, 32, 32, 3),\n",
    "    # 50000 is the batch size (total images), 32 is the height, 32 is the width,\n",
    "    # and 3 is the channels (RGB)\n",
    "\n",
    "    # But why won't we change the labels shape too?\n",
    "    # Because we don't need to, we're not going to use Conv2D layer\n",
    "    # for our labels, we're going to use Dense layer, and Dense layer\n",
    "    # requires the input shape to be (batch_size, input_size)\n",
    "    # So we don't need to reshape our labels, we just need to\n",
    "    # make sure that the input_size is 3072, and it is.\n",
    "    images, labels = unpicke_images()\n",
    "    images = images.reshape((images.shape[0], 3, 32, 32))\n",
    "    images = np.moveaxis(images, 1, -1)\n",
    "\n",
    "    # Before we return our images, we need to randomize it (shuffle)\n",
    "    # Why? Because we want to split our images into train and test set\n",
    "    # and we don't want the train set to be all cats and the test set to be all dogs\n",
    "    # So we need to randomize it first\n",
    "    # We're going to use np.random.permutation to randomize our images\n",
    "    # and we're going to use np.random.seed to make sure that the randomization\n",
    "    # is the same every time we run this code\n",
    "\n",
    "    random_seed = random.randint(1, 50000)\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "    randomize = np.random.permutation(len(images))\n",
    "    images = images[randomize]\n",
    "    labels = labels[randomize]\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "images, labels = load_images()\n",
    "\n",
    "with print_colored(bcolors.OKGREEN):\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets show the first 5 images with their labels\n",
    "for i in range(5):\n",
    "    print(f\"{bcolors.OKGREEN}Image label: {labels[i]}{bcolors.ENDC}\")\n",
    "    plt.imshow(images[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize our data\n",
    "images = images / 255.0\n",
    "\n",
    "# Let's check if our data is normalized\n",
    "with print_colored(bcolors.OKGREEN):\n",
    "    print(f\"Max value: {np.max(images)}\")\n",
    "    print(f\"Min value: {np.min(images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets split our data into train and test sets\n",
    "# We're going to use 80% of our data for training\n",
    "# and 20% of our data for testing\n",
    "train_images, test_images, validation_images = np.split(images, [int(\n",
    "    len(images) * 0.8), int(len(images) * 0.9)])\n",
    "train_labels, test_labels, validation_labels = np.split(labels, [int(\n",
    "    len(labels) * 0.8), int(len(labels) * 0.9)])\n",
    "\n",
    "with print_colored(bcolors.OKGREEN):\n",
    "    print(f\"Train images shape: {train_images.shape}\")\n",
    "    print(f\"Train labels shape: {train_labels.shape}\")\n",
    "    print(f\"Test images shape: {test_images.shape}\")\n",
    "    print(f\"Test labels shape: {test_labels.shape}\")\n",
    "    print(f\"Validation images shape: {validation_images.shape}\")\n",
    "    print(f\"Validation labels shape: {validation_labels.shape}\")\n",
    "\n",
    "    # We should have 40000 images for training, 10000 images for testing,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.6),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Our model:\n",
    "# 1. Conv2D layer with 32 filters, kernel size 3x3, relu activation function, and input shape (32, 32, 3)\n",
    "# 1.1 Those 32 filters will be applied to our input image, and each filter will produce a 2D activation map\n",
    "# 1.2 The kernel size 3x3 means that the filter will be 3x3 pixels\n",
    "# 1.3 The relu activation function will be applied to the activation map, and it will remove all negative values\n",
    "# 1.4 The input shape is (32, 32, 3), 32 is the height, 32 is the width, and 3 is the channels (RGB)\n",
    "# 2. MaxPooling2D layer with pool size 2x2\n",
    "# 2.1 This layer will reduce the size of the activation map by 2x2\n",
    "# 3. Conv2D layer with 64 filters, kernel size 3x3, relu activation function\n",
    "# 4. MaxPooling2D layer with pool size 2x2\n",
    "# 5. Conv2D layer with 64 filters, kernel size 3x3, relu activation function\n",
    "# 6. Flatten layer\n",
    "# 6.1 This layer will flatten our 2D activation map to 1D\n",
    "# 7. Dense layer with 64 neurons, relu activation function\n",
    "# 7.1 This layer will connect all neurons from the previous layer to this layer\n",
    "# 8. Dropout layer with 0.5 rate\n",
    "# 8.1 This layer will randomly drop 50% of the neurons\n",
    "# 9. Dense layer with 10 neurons, softmax activation function\n",
    "# 9.1 This layer will connect all neurons from the previous layer to this layer, softmax activation function will\n",
    "# normalize the output values to 0-1, and the sum of all output values will be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's compile our model\n",
    "model.compile(tf.keras.optimizers.Adam(0.001),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "# We're using Adam optimizer with learning rate 0.001, and sparse_categorical_crossentropy loss function\n",
    "# We're using sparse_categorical_crossentropy because our labels are not one-hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get a summary of our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='logs', histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to train our model\n",
    "history = model.fit(train_images, train_labels, epochs=50, validation_data=(\n",
    "    validation_images, validation_labels), callbacks=[tensorboard_callback], verbose=2)\n",
    "# history = model.fit(train_images, train_labels, epochs=50, validation_split=0.2, callbacks=[tensorboard_callback], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    fig, axs = plt.subplots(2)\n",
    "\n",
    "    # create accuracy subplot\n",
    "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
    "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    axs[0].legend(loc=\"lower right\")\n",
    "    axs[0].set_title(\"Accuracy eval\")\n",
    "\n",
    "    # create error subplot\n",
    "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
    "    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
    "    axs[1].set_ylabel(\"Error\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].legend(loc=\"upper right\")\n",
    "    axs[1].set_title(\"Error eval\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)\n",
    "\n",
    "with print_colored(bcolors.OKGREEN):\n",
    "    print(f\"Test loss: {history.history['val_loss'][-1]}\")\n",
    "    print(f\"Test accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "\n",
    "    print(f\"Train loss: {history.history['loss'][-1]}\")\n",
    "    print(f\"Train accuracy: {history.history['accuracy'][-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "precision = Precision()\n",
    "recall = Recall()\n",
    "\n",
    "for test in test_images:\n",
    "    X, y = test.reshape(1, 32, 32, 3), test_labels[0]\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred = np.argmax(y_pred, axis=1)[0]\n",
    "    precision.update_state([y], [y_pred])\n",
    "    recall.update_state([y], [y_pred])\n",
    "\n",
    "with print_colored(bcolors.OKGREEN):\n",
    "    print(f\"Precision: {precision.result().numpy()}\")\n",
    "    print(f\"Recall: {recall.result().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to test it ourselves!\n",
    "# We'll download some images on the internet, resize and test it\n",
    "\n",
    "# Download some images\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def download_test_images():\n",
    "    car_image_url = 'https://cdni.autocarindia.com/utils/imageresizer.ashx?n=https://cms.haymarketindia.net/model/uploads/modelimages/Hyundai-Grand-i10-Nios-200120231541.jpg&w=32&h=32&q=75&c=1'\n",
    "    dog_image_url = 'https://cdn.pixabay.com/photo/2016/12/13/05/15/puppy-1903313_960_720.jpg'\n",
    "    cat_image_url = 'https://cdn.pixabay.com/photo/2017/02/20/18/03/cat-2083492_960_720.jpg'\n",
    "\n",
    "    car_image_file = 'car.jpg'\n",
    "    dog_image_file = 'dog.jpg'\n",
    "    cat_image_file = 'cat.jpg'\n",
    "\n",
    "    if not os.path.exists(car_image_file):\n",
    "        r = requests.get(car_image_url, stream=True)\n",
    "        with open(car_image_file, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=1024):\n",
    "                f.write(chunk)\n",
    "\n",
    "    if not os.path.exists(dog_image_file):\n",
    "        r = requests.get(dog_image_url, stream=True)\n",
    "        with open(dog_image_file, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=1024):\n",
    "                f.write(chunk)\n",
    "\n",
    "    if not os.path.exists(cat_image_file):\n",
    "        r = requests.get(cat_image_url, stream=True)\n",
    "        with open(cat_image_file, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=1024):\n",
    "                f.write(chunk)\n",
    "\n",
    "    return car_image_file, dog_image_file, cat_image_file\n",
    "\n",
    "\n",
    "car_image_file, dog_image_file, cat_image_file = download_test_images()\n",
    "\n",
    "# Resize the images\n",
    "\n",
    "\n",
    "def resize_image(image_file):\n",
    "    image = Image.open(image_file)\n",
    "    image = image.resize((32, 32))\n",
    "    image.save(image_file)\n",
    "\n",
    "\n",
    "resize_image(car_image_file)\n",
    "resize_image(dog_image_file)\n",
    "resize_image(cat_image_file)\n",
    "\n",
    "# Load the images\n",
    "\n",
    "\n",
    "def load_test_images():\n",
    "    images = []\n",
    "    for image_file in [car_image_file, dog_image_file, cat_image_file]:\n",
    "        image = Image.open(image_file)\n",
    "        image = np.array(image)\n",
    "        images.append(image)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "test_images = load_test_images()\n",
    "\n",
    "# Show the images\n",
    "for image in test_images:\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "# Normalize the images\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Predict the images\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "# Show the predictions\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print(f\"{bcolors.OKGREEN}Prediction: {np.argmax(prediction)}{bcolors.ENDC}\")\n",
    "    plt.imshow(test_images[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now our job is done, we can save our model\n",
    "model.save('model.h5')\n",
    "\n",
    "# If you want to recover the last training session, you can use this code\n",
    "# model = tf.keras.models.load_model('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
